# -*- coding: utf-8 -*-
"""Deep Learning Process for Cancer .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I7QW2AA8mla7Oltysm_Gs-exYUSr91Xg
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn.datasets
from sklearn.model_selection import train_test_split

breast_cancer_dataset= sklearn.datasets.load_breast_cancer()

data_frame = pd.DataFrame(breast_cancer_dataset.data, columns=breast_cancer_dataset.feature_names)

data_frame.head()

data_frame['label']  = breast_cancer_dataset.target

data_frame.head()

data_frame.tail()

data_frame.isnull().sum()

data_frame["label"].value_counts()

data_frame.groupby('label').mean()

X=data_frame.drop(columns = 'label',axis =1)
Y= data_frame['label']
print(X)

print(Y)

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2,random_state =2)

print(X.shape,X_train.shape,X_test.shape)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train_std = scaler.fit_transform(X_train)

X_test_std = scaler.transform(X_test)

print(X_train_std )

"""Building a  Neural Network

random seed helps you to get the same accuracy score all the time
"""

import tensorflow as tf
tf.random.set_seed(3)
from tensorflow import keras

# setting up the layers of neural network
model = keras.Sequential([
                           keras.layers.Flatten(input_shape =(30,)), # flatten is used to flatten the data which is in matrix form and it is the input layer
                           keras.layers.Dense(20 ,activation= 'relu'),# this is the second layer
                           keras.layers.Dense(20 ,activation= 'relu'),
                           keras.layers.Dense(2,activation ='sigmoid')# this is the output layer
])

# compiling neural network
model.compile(optimizer = 'adam',
              loss ='sparse_categorical_crossentropy',
              metrics = ['accuracy'])

# training the neural network

history = model.fit(X_train_std, Y_train, validation_split=0.1, epochs=10)

"""Visulaizing the data accuracy and loss"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])


plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')

plt.legend(['training data','validation data'],loc ='lower right')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])


plt.title('model accuracy')
plt.ylabel('loss')
plt.xlabel('epoch')

plt.legend(['training data','validation data'],loc ='upper right')

"""Accuracy of the model on test data"""

loss,accuracy = model.evaluate(X_test_std,Y_test)
print(accuracy)

print(X_test_std.shape)
print(X_test_std[0])

Y_pred =model.predict(X_test_std)

print(Y_pred.shape)
print(Y_pred[0])

print(X_test_std)

print(Y_pred)

"""model.predict() gives the prediction probability of each class for the  data"""

#converting The prediction probability to class labels
Y_pred_labels =[np.argmax(i) for i in Y_pred]
print(Y_pred_labels)

"""Building the predictive system"""

input_data = ()

input_data_as_numpy_array = np.asarray(input_data)

input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

input_data_std = scaler.transform(input_data_reshaped)

prediction = model.predict(input_data_std)

print(prediction)

prediction_label = [np.argmax(prediction)]
print (prediction_label)


if(prediction_label[0] == 0):
  print("the tumor is Malignant")

else:
  print("the tumor is Benign")