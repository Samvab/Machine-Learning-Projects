# -*- coding: utf-8 -*-
"""P.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bp2hzvVePWQJos0NkkpUm-XXnPmwIwtS
"""



# sustainability_streamlit_app.py
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import pickle
from datetime import datetime

class SustainabilityEngagementPredictor:
    def __init__(self):
        self.model = None
        self.scaler = None
        self.label_encoders = {}
        self.mapping_data = {}

    def create_sample_data(self):
        """Create realistic sample data based on sustainability content patterns"""
        np.random.seed(42)

        data = {
            'platform': np.random.choice(['Facebook', 'LinkedIn', 'X', 'Instagram', 'TikTok', 'Reddit', 'Medium'], 500),
            'climate_topic': np.random.choice([
                'Waste Reduction', 'Water Management', 'Sustainable Tourism', 'Energy Storage',
                'Climate Emergency', 'Ocean Acidification', 'Clean Transportation', 'Renewable Energy',
                'Biodiversity', 'Circular Economy', 'Sustainable Agriculture', 'Green Building'
            ], 500),
            'user_followers': np.random.lognormal(12, 1.5, 500).astype(int),
            'user_location': np.random.choice([
                'Tokyo', 'Stockholm', 'Brussels', 'Singapore', 'Edinburgh', 'New York',
                'London', 'Berlin', 'Sydney', 'Toronto', 'Oslo', 'Shanghai', 'Dubai'
            ], 500),
            'post_sentiment': np.random.choice(['Positive', 'Negative', 'Neutral'], 500, p=[0.6, 0.2, 0.2]),
            'post_date': pd.date_range('2024-01-01', periods=500, freq='H')
        }

        df = pd.DataFrame(data)

        # Create realistic engagement patterns based on platform and time
        base_engagement = {
            'Instagram': (800, 3000),
            'TikTok': (1000, 4000),
            'Facebook': (500, 2000),
            'X': (300, 1500),
            'LinkedIn': (200, 1200),
            'Reddit': (150, 1000),
            'Medium': (100, 800)
        }

        df['engagement_likes'] = 0
        df['engagement_shares'] = 0
        df['engagement_comments'] = 0

        for platform in base_engagement.keys():
            mask = df['platform'] == platform
            size = mask.sum()

            # Higher engagement for positive sentiment
            sentiment_multiplier = np.where(df['post_sentiment'][mask] == 'Positive', 1.3,
                                          np.where(df['post_sentiment'][mask] == 'Negative', 0.8, 1.0))

            # Time-based engagement (higher during 8-20 hours)
            hour = df['post_date'][mask].dt.hour
            time_multiplier = 0.5 + (np.sin((hour - 14) * np.pi / 12) + 1) / 2

            df.loc[mask, 'engagement_likes'] = (np.random.uniform(*base_engagement[platform], size) *
                                              sentiment_multiplier * time_multiplier).astype(int)
            df.loc[mask, 'engagement_shares'] = (df['engagement_likes'][mask] *
                                               np.random.uniform(0.1, 0.3, size)).astype(int)
            df.loc[mask, 'engagement_comments'] = (df['engagement_likes'][mask] *
                                                 np.random.uniform(0.05, 0.15, size)).astype(int)

        return df

    def train_model(self):
        """Train the engagement prediction model"""
        with st.spinner("Creating training data and training model..."):
            df = self.create_sample_data()

            # Calculate engagement score (weighted sum)
            df['engagement_score'] = (df['engagement_likes'] * 0.4 +
                                     df['engagement_shares'] * 0.3 +
                                     df['engagement_comments'] * 0.3)

            # Feature engineering
            df['post_hour'] = df['post_date'].dt.hour
            df['post_day'] = df['post_date'].dt.day
            df['post_month'] = df['post_date'].dt.month
            df['post_dayofweek'] = df['post_date'].dt.dayofweek

            # Encode categorical variables
            categorical_cols = ['platform', 'climate_topic', 'user_location', 'post_sentiment']

            for col in categorical_cols:
                le = LabelEncoder()
                df[col + '_encoded'] = le.fit_transform(df[col].astype(str))
                self.label_encoders[col] = le

            # Select features for modeling
            features = ['post_hour', 'post_day', 'post_month', 'post_dayofweek',
                       'platform_encoded', 'climate_topic_encoded',
                       'user_followers', 'user_location_encoded',
                       'post_sentiment_encoded']

            X = df[features]
            y = df['engagement_score']

            # Split the data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            # Scale numerical features
            self.scaler = StandardScaler()
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)

            # Train Random Forest model
            self.model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)
            self.model.fit(X_train_scaled, y_train)

            # Make predictions
            y_pred = self.model.predict(X_test_scaled)

            # Evaluate model
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            r2 = r2_score(y_test, y_pred)

            # Save mapping data
            self.mapping_data = {}
            for col in categorical_cols:
                self.mapping_data[col] = dict(zip(self.label_encoders[col].classes_,
                                               self.label_encoders[col].transform(self.label_encoders[col].classes_)))

            return rmse, r2, df

    def predict_engagement(self, platform, climate_topic, sentiment, hour, day, month, dayofweek, followers, location):
        """Predict engagement score for given parameters"""
        try:
            # Encode categorical variables
            platform_encoded = self.mapping_data['platform'][platform]
            climate_topic_encoded = self.mapping_data['climate_topic'][climate_topic]
            sentiment_encoded = self.mapping_data['post_sentiment'][sentiment]
            location_encoded = self.mapping_data['user_location'][location]

            # Create feature array
            features = np.array([[hour, day, month, dayofweek, platform_encoded,
                                 climate_topic_encoded, followers, location_encoded,
                                 sentiment_encoded]])

            # Scale features
            features_scaled = self.scaler.transform(features)

            # Predict engagement
            engagement_score = self.model.predict(features_scaled)[0]

            return max(0, engagement_score)  # Ensure non-negative score

        except KeyError as e:
            st.error(f"Error: '{e}' not found in training data. Please use valid categories.")
            return None

    def find_optimal_platform(self, climate_topic, sentiment, hour, day, month, dayofweek, followers, location):
        """Find the best platform for given content"""
        platforms = list(self.mapping_data['platform'].keys())
        results = {}

        for platform in platforms:
            score = self.predict_engagement(platform, climate_topic, sentiment, hour, day,
                                          month, dayofweek, followers, location)
            if score is not None:
                results[platform] = score

        if results:
            best_platform = max(results, key=results.get)
            return best_platform, results[best_platform], results
        return None, None, {}

    def find_optimal_time(self, platform, climate_topic, sentiment, day, month, dayofweek, followers, location):
        """Find the best posting time for given content"""
        results = {}

        for hour in range(24):
            score = self.predict_engagement(platform, climate_topic, sentiment, hour, day,
                                          month, dayofweek, followers, location)
            if score is not None:
                results[hour] = score

        if results:
            best_hour = max(results, key=results.get)
            return best_hour, results[best_hour], results
        return None, None, {}

def main():
    """Main Streamlit app function"""
    st.set_page_config(
        page_title="Sustainability Engagement Predictor",
        page_icon="🌱",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Custom CSS
    st.markdown("""
        <style>
        .main-header {font-size: 3rem; color: #2E8B57; text-align: center;}
        .sub-header {font-size: 1.5rem; color: #3CB371;}
        .metric-card {background-color: #F0FFF0; padding: 20px; border-radius: 10px; margin: 10px;}
        </style>
    """, unsafe_allow_html=True)

    st.markdown('<h1 class="main-header">🌱 Sustainability Content Engagement Predictor</h1>', unsafe_allow_html=True)
    st.markdown("Predict engagement scores and optimize your posting strategy for sustainability content")

    # Initialize predictor
    if 'predictor' not in st.session_state:
        st.session_state.predictor = SustainabilityEngagementPredictor()
        rmse, r2, df = st.session_state.predictor.train_model()
        st.session_state.model_metrics = {'rmse': rmse, 'r2': r2}
        st.session_state.training_data = df

    # Sidebar for input
    with st.sidebar:
        st.header("📊 Post Parameters")

        platform = st.selectbox("Platform", options=list(st.session_state.predictor.mapping_data['platform'].keys()))
        climate_topic = st.selectbox("Climate Topic", options=list(st.session_state.predictor.mapping_data['climate_topic'].keys()))
        sentiment = st.selectbox("Sentiment", options=list(st.session_state.predictor.mapping_data['post_sentiment'].keys()))
        location = st.selectbox("Location", options=list(st.session_state.predictor.mapping_data['user_location'].keys()))

        col1, col2 = st.columns(2)
        with col1:
            hour = st.slider("Hour", 0, 23, 14)
            day = st.slider("Day", 1, 31, 15)
        with col2:
            month = st.slider("Month", 1, 12, 6)
            dayofweek = st.selectbox("Day of Week", options=["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"])

        followers = st.number_input("Followers Count", min_value=1000, max_value=2000000, value=100000, step=1000)

        day_map = {"Monday": 0, "Tuesday": 1, "Wednesday": 2, "Thursday": 3, "Friday": 4, "Saturday": 5, "Sunday": 6}
        dayofweek_encoded = day_map[dayofweek]

    # Main content
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown('<h2 class="sub-header">📈 Engagement Prediction</h2>', unsafe_allow_html=True)

        if st.button("🚀 Predict Engagement", use_container_width=True):
            score = st.session_state.predictor.predict_engagement(
                platform, climate_topic, sentiment, hour, day, month, dayofweek_encoded, followers, location
            )

            if score is not None:
                st.session_state.current_score = score

                # Display prediction
                st.metric("Predicted Engagement Score", f"{score:.2f}")

                # Optimization analysis
                st.markdown('<h3 class="sub-header">🔍 Optimization Analysis</h3>', unsafe_allow_html=True)

                # Platform optimization
                best_platform, platform_score, platform_results = st.session_state.predictor.find_optimal_platform(
                    climate_topic, sentiment, hour, day, month, dayofweek_encoded, followers, location
                )

                # Time optimization
                best_hour, hour_score, hour_results = st.session_state.predictor.find_optimal_time(
                    platform, climate_topic, sentiment, day, month, dayofweek_encoded, followers, location
                )

                # Display optimizations
                if best_platform:
                    st.info(f"**Best Platform**: {best_platform} (Score: {platform_score:.2f})")

                if best_hour is not None:
                    st.info(f"**Best Posting Hour**: {best_hour}:00 (Score: {hour_score:.2f})")

                # Recommendations
                st.markdown('<h3 class="sub-header">💡 Recommendations</h3>', unsafe_allow_html=True)

                if best_platform and platform_score > score * 1.1:
                    st.success(f"✅ Switch to **{best_platform}** for better engagement")

                if best_hour is not None and hour_score > score * 1.1:
                    st.success(f"✅ Post at **{best_hour}:00** for optimal timing")

                if best_platform or best_hour is not None:
                    max_score = max(platform_score if best_platform else 0, hour_score if best_hour is not None else 0)
                    improvement = max_score - score
                    if improvement > 0:
                        st.success(f"📈 Potential improvement: **+{improvement:.2f}** points ({improvement/score*100:.1f}%)")

    with col2:
        st.markdown('<h2 class="sub-header">📊 Model Info</h2>', unsafe_allow_html=True)

        if 'model_metrics' in st.session_state:
            st.metric("Model R² Score", f"{st.session_state.model_metrics['r2']:.4f}")
            st.metric("Model RMSE", f"{st.session_state.model_metrics['rmse']:.2f}")

        # Feature importance
        if st.session_state.predictor.model is not None:
            feature_importance = pd.DataFrame({
                'Feature': ['Hour', 'Day', 'Month', 'Day of Week', 'Platform',
                           'Climate Topic', 'Followers', 'Location', 'Sentiment'],
                'Importance': st.session_state.predictor.model.feature_importances_
            }).sort_values('Importance', ascending=False)

            st.markdown("**Feature Importance:**")
            st.dataframe(feature_importance, use_container_width=True)

    # Visualization section
    st.markdown("---")
    st.markdown('<h2 class="sub-header">📊 Platform Performance</h2>', unsafe_allow_html=True)

    if 'training_data' in st.session_state:
        platform_stats = st.session_state.training_data.groupby('platform').agg({
            'engagement_likes': 'mean',
            'engagement_shares': 'mean',
            'engagement_comments': 'mean',
            'engagement_score': 'mean'
        }).round(2)

        col1, col2 = st.columns(2)

        with col1:
            st.bar_chart(platform_stats['engagement_score'])
            st.caption("Average Engagement Score by Platform")

        with col2:
            fig, ax = plt.subplots(figsize=(10, 6))
            platform_stats[['engagement_likes', 'engagement_shares', 'engagement_comments']].plot(kind='bar', ax=ax)
            ax.set_title("Engagement Metrics by Platform")
            ax.set_ylabel("Average Count")
            plt.xticks(rotation=45)
            st.pyplot(fig)

if __name__ == "__main__":
    main()