# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nr1PWPKlT1VlsQK32LBWPS8hlo5fruSb
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import re
import base64
from io import BytesIO

# Set page configuration
st.set_page_config(
    page_title="Laptop Price Predictor",
    page_icon="ðŸ’»",
    layout="wide"
)

# App title and description
st.title("ðŸ’» Laptop Price Predictor")
st.markdown("""
This app predicts laptop prices based on specifications like company, type, screen details, CPU, RAM, etc.
""")

# Function to load data
@st.cache_data
def load_data():
    # You would replace this with your own dataset
    # For demonstration, I'm creating a sample dataset that you should replace with real laptop data
    # url = "https://raw.githubusercontent.com/SD1407/Laptop-Price-Prediction-Dataset/master/laptop_data.csv"
    try:
        df = pd.read_csv("laptop_data (1).csv")
        return df
    except:
        st.error("Could not load dataset. Please check the URL or upload your own dataset.")
        return None

# Load the dataset
df = load_data()

if df is not None:
    # Display dataset info in expander
    with st.expander("Dataset Information"):
        st.write(f"Dataset Shape: {df.shape}")
        st.write("Sample Data:")
        st.dataframe(df.head())

        # Check for missing values
        missing_values = df.isnull().sum()
        if missing_values.sum() > 0:
            st.write("Missing Values:")
            st.write(missing_values[missing_values > 0])

    # Data preprocessing functions
    def preprocess_data(df):
        # Make a copy to avoid modifying the original
        data = df.copy()

        # Extract CPU information
        data['Processor_Brand'] = data['Cpu'].apply(lambda x: re.split('\\s', x)[0] if pd.notna(x) else x)
        data['Processor_Name'] = data['Cpu'].apply(lambda x: ' '.join(re.split('\\s', x)[1:3]) if pd.notna(x) else x)
        data['Processor_Speed'] = data['Cpu'].apply(lambda x: float(re.search(r'([\d.]+)GHz', x).group(1)) if pd.notna(x) and re.search(r'([\d.]+)GHz', x) else np.nan)

        # Extract RAM
        data['Ram'] = data['Ram'].apply(lambda x: int(re.search(r'(\d+)GB', x).group(1)) if pd.notna(x) else np.nan)

        # Extract memory information
        data['Memory_Type'] = data['Memory'].apply(lambda x: re.search(r'(SSD|HDD|Flash Storage|Hybrid)', x).group(1) if pd.notna(x) and re.search(r'(SSD|HDD|Flash Storage|Hybrid)', x) else 'Other')
        data['Memory_Size'] = data['Memory'].apply(lambda x:
            int(re.search(r'(\d+)GB', x).group(1)) if pd.notna(x) and re.search(r'(\d+)GB', x)
            else (int(re.search(r'(\d+)TB', x).group(1)) * 1000 if pd.notna(x) and re.search(r'(\d+)TB', x) else np.nan))

        # Extract screen resolution
        data['ScreenResolution'] = data['ScreenResolution'].fillna('Unknown')
        data['TouchScreen'] = data['ScreenResolution'].apply(lambda x: 1 if 'Touch' in x else 0)
        data['IPS'] = data['ScreenResolution'].apply(lambda x: 1 if 'IPS' in x else 0)

        # Extract screen resolution values (width x height)
        data['Resolution'] = data['ScreenResolution'].apply(lambda x:
            re.search(r'(\d+x\d+)', x).group(1) if re.search(r'(\d+x\d+)', x) else '1366x768')
        data['Resolution_Width'] = data['Resolution'].apply(lambda x: int(x.split('x')[0]))
        data['Resolution_Height'] = data['Resolution'].apply(lambda x: int(x.split('x')[1]))
        data['PPI'] = ((data['Resolution_Width']**2 + data['Resolution_Height']**2)**0.5/data['Inches']).astype(int)

        # Extract GPU information
        data['Gpu_Brand'] = data['Gpu'].apply(lambda x: x.split()[0] if pd.notna(x) else x)

        # Clean up Weight column
        data['Weight'] = data['Weight'].apply(lambda x: float(re.search(r'([\d.]+)kg', str(x).lower()).group(1)) if pd.notna(x) else np.nan)

        # Select features for model training
        features = ['Company', 'TypeName', 'Inches', 'TouchScreen', 'IPS', 'PPI',
                  'Processor_Brand', 'Ram', 'Memory_Type', 'Memory_Size',
                  'Gpu_Brand', 'OpSys', 'Weight']

        return data, features

    # Preprocess the data
    processed_df, features = preprocess_data(df)

    # Split data for training and testing
    X = processed_df[features]
    y = processed_df['Price']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Prepare transformers for categorical and numerical features
    categorical_features = ['Company', 'TypeName', 'Processor_Brand', 'Memory_Type', 'Gpu_Brand', 'OpSys']
    numerical_features = ['Inches', 'TouchScreen', 'IPS', 'PPI', 'Ram', 'Memory_Size', 'Weight']

    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    numerical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', categorical_transformer, categorical_features),
            ('num', numerical_transformer, numerical_features)
        ])

    # Create and train the model
    model = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
    ])

    with st.spinner('Training model... Please wait.'):
        model.fit(X_train, y_train)

    # Model evaluation
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)

    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
    train_r2 = r2_score(y_train, y_pred_train)
    test_r2 = r2_score(y_test, y_pred_test)

    with st.expander("Model Performance"):
        col1, col2 = st.columns(2)
        with col1:
            st.write("Training RMSE:", round(train_rmse, 2))
            st.write("Testing RMSE:", round(test_rmse, 2))
        with col2:
            st.write("Training RÂ²:", round(train_r2, 2))
            st.write("Testing RÂ²:", round(test_r2, 2))

        # Visualize predictions vs actual
        fig, ax = plt.subplots(1, 2, figsize=(12, 5))

        ax[0].scatter(y_train, y_pred_train, alpha=0.5)
        ax[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')
        ax[0].set_title('Training Data: Actual vs Predicted')
        ax[0].set_xlabel('Actual Price')
        ax[0].set_ylabel('Predicted Price')

        ax[1].scatter(y_test, y_pred_test, alpha=0.5)
        ax[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
        ax[1].set_title('Testing Data: Actual vs Predicted')
        ax[1].set_xlabel('Actual Price')
        ax[1].set_ylabel('Predicted Price')

        plt.tight_layout()
        st.pyplot(fig)

    # Get unique values for each categorical feature
    companies = sorted(processed_df['Company'].dropna().unique())
    type_names = sorted(processed_df['TypeName'].dropna().unique())
    processor_brands = sorted(processed_df['Processor_Brand'].dropna().unique())
    memory_types = sorted(processed_df['Memory_Type'].dropna().unique())
    gpu_brands = sorted(processed_df['Gpu_Brand'].dropna().unique())
    os_options = sorted(processed_df['OpSys'].dropna().unique())

    # User input form for prediction
    st.header("Enter Laptop Specifications")
    st.markdown("Fill in the laptop specifications to get a price prediction.")

    col1, col2, col3 = st.columns(3)

    with col1:
        company = st.selectbox("Company", companies)
        type_name = st.selectbox("Type", type_names)
        inches = st.slider("Screen Size (inches)", min_value=10.0, max_value=20.0, value=15.6, step=0.1)
        touch_screen = st.selectbox("Touch Screen", ["No", "Yes"])
        touch_screen = 1 if touch_screen == "Yes" else 0
        ips_panel = st.selectbox("IPS Panel", ["No", "Yes"])
        ips_panel = 1 if ips_panel == "Yes" else 0

    with col2:
        processor_brand = st.selectbox("Processor Brand", processor_brands)
        ram = st.selectbox("RAM (GB)", [2, 4, 8, 16, 32, 64])
        memory_type = st.selectbox("Storage Type", memory_types)
        memory_size = st.number_input("Storage Size (GB)", min_value=32, max_value=4000, value=512)

    with col3:
        gpu_brand = st.selectbox("GPU Brand", gpu_brands)
        os = st.selectbox("Operating System", os_options)
        weight = st.slider("Weight (kg)", min_value=0.5, max_value=5.0, value=2.0, step=0.1)

    # Calculate PPI (Pixels Per Inch) based on typical resolutions for screen sizes
    # This is a simplified approach - in a real app, you might want to let users select resolution
    resolution_mapping = {
        (10, 12): (1366, 768),  # smaller screens
        (12, 14): (1920, 1080), # medium screens
        (14, 16): (1920, 1080), # common laptop size
        (16, 18): (2560, 1440), # larger laptops
        (18, 20): (3840, 2160)  # large/premium laptops
    }

    res_width, res_height = None, None
    for (min_size, max_size), (width, height) in resolution_mapping.items():
        if min_size <= inches < max_size:
            res_width, res_height = width, height
            break

    if res_width is None:  # Default fallback
        res_width, res_height = 1920, 1080

    ppi = int(((res_width**2 + res_height**2)**0.5)/inches)

    # Create input dataframe for prediction
    input_data = pd.DataFrame({
        'Company': [company],
        'TypeName': [type_name],
        'Inches': [inches],
        'TouchScreen': [touch_screen],
        'IPS': [ips_panel],
        'PPI': [ppi],
        'Processor_Brand': [processor_brand],
        'Ram': [ram],
        'Memory_Type': [memory_type],
        'Memory_Size': [memory_size],
        'Gpu_Brand': [gpu_brand],
        'OpSys': [os],
        'Weight': [weight]
    })

    # Make prediction when user clicks the button
    if st.button("Predict Price"):
        with st.spinner("Calculating price..."):
            prediction = model.predict(input_data)

            # Display prediction
            st.success(f"### Estimated Laptop Price: ${prediction[0]:,.2f}")

            # Display similar laptops for reference
            st.subheader("Similar Laptops in Dataset")

            # Find similar laptops based on specs
            similar_laptops = processed_df[
                (processed_df['Company'] == company) &
                (processed_df['TypeName'] == type_name) &
                (processed_df['Ram'] == ram) &
                (processed_df['Memory_Type'] == memory_type)
            ].sort_values(by='Price')

            if len(similar_laptops) > 0:
                st.dataframe(similar_laptops[['Company', 'TypeName', 'Inches', 'Ram',
                                            'Memory_Type', 'Memory_Size', 'Processor_Brand',
                                            'Gpu_Brand', 'Weight', 'Price']].head(5))
            else:
                st.info("No very similar laptops found in the dataset.")

    # Download trained model
    def download_model():
        import pickle
        buffer = BytesIO()
        pickle.dump(model, buffer)
        buffer.seek(0)
        return buffer

    with st.expander("Download Resources"):
        col1, col2 = st.columns(2)

        with col1:
            st.download_button(
                label="Download Trained Model",
                data=download_model(),
                file_name="laptop_price_model.pkl",
                mime="application/octet-stream"
            )

        with col2:
            # Create sample deployment code
            deployment_code = """
import streamlit as st
import pandas as pd
import pickle
import re
import numpy as np

# Load the model
with open('laptop_price_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Rest of your app code here
# ...
"""
            st.download_button(
                label="Download Deployment Code",
                data=deployment_code,
                file_name="deploy_app.py",
                mime="text/plain"
            )

else:
    st.error("Dataset could not be loaded. Please check your connection or upload a dataset.")

    # File uploader as alternative
    uploaded_file = st.file_uploader("Upload your laptop dataset (CSV)", type=["csv"])
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.success("Dataset uploaded successfully!")
        st.dataframe(df.head())